# Deep learning reading list from Ilya Sutskever
> 深度学习精炼秘笈

> til, Ilya sutskever gave john carmack this reading list of approx 30 research papers and said, ‘If you really learn all of these, you’ll know 90% of what matters today.’
<br>

[[Twitter Post]](https://twitter.com/keshavchan/status/1787861946173186062) [[Arc.net Link]](https://arc.net/folder/D0472A20-9C20-4D3F-B145-D2865C0A9FEE)
<br>

## 

- **The Annotated Transformer.** Sasha Rush, et al. [[Blog]](https://nlp.seas.harvard.edu/annotated-transformer/) [[Code]](https://github.com/harvardnlp/annotated-transformer/) [[pdf]](pdfs/annotated-transformer.pdf)
- **The First Law of Complexodynamics.** Scott Aaronson. [[Blog]](https://scottaaronson.blog/?p=762) [[pdf]](pdfs/first-law-of-complexodynamics.pdf)
- **The Unreasonable Effectiveness of Recurrent Neural Networks.** Andrej Karpathy. [[Blog]](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) [[Code]](https://github.com/karpathy/char-rnn) [[pdf]](pdfs/unreasonable-effectiveness-rnns.pdf)
- **Understanding LSTM Networks.** Christopher Olah. [[Blog]](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) [[pdf]](pdfs/understanding-lstm-networks.pdf)
- **Recurrent Neural Network Regularization.** Wojciech Zaremba, et al. [[ArXiv]](https://arxiv.org/abs/1409.2329) [[pdf]](https://arxiv.org/pdf/1409.2329) [[Code]](https://github.com/wojzaremba/lstm) [[pdf]](pdfs/1409.2329v5.pdf)
- **Keeping Neural Networks Simple by Minimizing the Description Length of the Weights.** Geoffrey E. Hinton and Drew van Camp. [[Paper]](https://dl.acm.org/doi/10.1145/168304.168306) [[pdf]](https://www.cs.toronto.edu/~hinton/absps/colt93.pdf) [[pdf]](pdfs/colt93.pdf)
- **Pointer Networks.** Oriol Vinyals, et al. [[Paper]](https://papers.nips.cc/paper/5866-pointer-networks) [[pdf]](https://arxiv.org/pdf/1506.03134) [[pdf]](pdfs/1506.03134v2.pdf)
- **ImageNet Classification with Deep Convolutional Neural Networks.** Alex Krizhevsky, et al. [[Paper]](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks) [[pdf]](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf) [[pdf]](pdfs/NIPS-2012-imagenet-classification-with-deep-convolutional-neural-networks-Paper.pdf)
- **Order Matters: Sequence to sequence for sets.** Oriol Vinyals, et al. [[ArXiv]](https://arxiv.org/abs/1511.06391) [[pdf]](https://arxiv.org/pdf/1511.06391) [[pdf]](pdfs/1511.06391v4.pdf)
- **GPipe: Easy Scaling with Micro-Batch Pipeline Parallelism.** Yanping Huang, et al. [[ArXiv]](https://arxiv.org/abs/1811.06965) [[pdf]](https://arxiv.org/pdf/1811.06965) [[pdf]](pdfs/1811.06965v5.pdf)
- **Deep Residual Learning for Image Recognition.** Kaiming He, et al. [[pdf]](https://arxiv.org/pdf/1512.03385) [[pdf]](pdfs/1512.03385v1%20-%20Deep%20Residual%20Learning%20for%20Image%20Recognition.pdf)
- **Multi-Scale Context Aggregation by Dilated Convolutions.** Fisher Yu and Vladlen Koltun. [[pdf]](https://arxiv.org/pdf/1511.07122) [[pdf]](pdfs/1511.07122.pdf)
- **Neural Message Passing for Quantum Chemistry.** Justin Gilmer, et al. [[pdf]](https://arxiv.org/pdf/1704.01212) [[pdf]](pdfs/1704.01212v2.pdf)
- **Attention Is All You Need.** Ashish Vaswani, et al. [[pdf]](https://arxiv.org/pdf/1706.03762) [[pdf]](pdfs/1706.03762v7.pdf)
- **Neural Machine Translation by Jointly Learning to Align and Translate.** Dzmitry Bahdanau, et al. [[pdf]](https://arxiv.org/pdf/1409.0473) [[pdf]](pdfs/1409.0473v7.pdf)
- **Identity Mappings in Deep Residual Networks.** Kaiming He, et al. [[pdf]](https://arxiv.org/pdf/1603.05027) [[pdf]](pdfs/1603.05027v3.pdf)
- **A simple neural network module for relational reasoning.** Adam Santoro, et al. [[pdf]](https://arxiv.org/pdf/1706.01427) [[pdf]](pdfs/1706.01427v1.pdf)
- **Variational Lossy Autoencoder.** Xi Chen, et al. [[pdf]](https://arxiv.org/pdf/1611.02731) [[pdf]](pdfs/1611.02731v2.pdf)
- **Relational recurrent neural networks.** Adam Santoro, et al. [[pdf]](https://arxiv.org/pdf/1806.01822) [[pdf]](pdfs/1806.01822v2.pdf)
- **Quantifying the Rise and Fall of Complexity in Closed Systems: The Coffee Automaton.** Scott Aaronson, et al. [[pdf]](https://www.scottaaronson.com/papers/coffee.pdf) [[pdf]](pdfs/coffee-automaton.pdf)
- **Neural Turing Machines.** Alex Graves, et al. [[pdf]](https://arxiv.org/pdf/1410.5401) [[pdf]](pdfs/1410.5401v2.pdf)
- **Deep Speech 2: End-to-End Speech Recognition in English and Mandarin.** Dario Amodei, et al. [[pdf]](https://arxiv.org/pdf/1512.02595) [[pdf]](pdfs/1512.02595v1.pdf)
- **Scaling Laws for Neural Language Models.** Jared Kaplan, et al. [[pdf]](https://arxiv.org/pdf/2001.08361) [[pdf]](pdfs/2001.08361v1.pdf)
- **A Tutorial Introduction to the Minimum Description Length Principle.** Peter Grunwald. [[pdf]](https://arxiv.org/pdf/math/0406077) [[pdf]](pdfs/0406077v1.pdf)
- **Machine Super Intelligence.** Shane Legg. [[pdf]](pdfs/Machine_Super_Intelligence.pdf)
- **Kolmogorov Complexity and Algorithmic Randomness.** A.Shen, V. A. Uspensky, and N. Vereshchagin. [[pdf]](pdfs/kolmogorov-complexity-and-algorithmic-randomness.pdf)
- **CS231n: Convolutional Neural Networks for Visual Recognition.** [[Course website]](http://cs231n.stanford.edu/) [[pdf snapshot]](pdfs/cs231n.pdf)
